\relax 
\citation{P6}
\@writefile{toc}{\contentsline {title}{A Composable Strategy for Shredded Document Reconstruction}{1}}
\@writefile{toc}{\authcount {2}}
\@writefile{toc}{\contentsline {author}{Razvan Ranca \and Iain Murray}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{P1}
\citation{P2}
\citation{P3,P4}
\citation{P1,P2,P3,P4,P7}
\citation{P7}
\citation{P5}
\citation{P8}
\citation{P9}
\citation{P10}
\citation{P11,P12}
\citation{P5,P10}
\citation{P14}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Probabilistic Score}{2}}
\citation{P7}
\citation{P8}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Figures {\bf  a},{\bf  b} and {\bf  c} show comparisons between our method and the most common previously used function. A sample word from each document is shown in the upper right corners. Figure {\bf  d} shows the improvement obtained by composing our function with another, very simple, probabilistic model.\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:scoreComp}{{1}{3}}
\citation{P13}
\citation{P5}
\citation{P3}
\citation{P4}
\citation{P3}
\citation{P4}
\@writefile{toc}{\contentsline {section}{\numberline {4}``Kruskal-Inspired" Heuristic Search}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Figure {\bf  a} shows the performance of our method compared to that of two heuristics introduced in \cite  {P3}. Here the X-axis shows how many moves would have to be performed to get from the outputted solution to the correct solution. Figure {\bf  b} shows the scalability of our approach when compared to the aforementioned heuristics and a few top down optimizing searches introduced in \cite  {P4} (ACO is an Ant Colony Optimization, while $HV^2$ and $BV^2$ are genetic algorithms).\relax }}{4}}
\newlabel{fig:searchScal}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The reduction in search space corresponding to 3 stopping conditions. ``Search space reduction" is defined as ${\begingroup \unhbox \voidb@x \hbox {Final no. pieces}\endgroup \over \unhbox \voidb@x \hbox {Initial no. pieces}}$.\relax }}{5}}
\newlabel{fig:searchReduct}{{3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The effect the error in score has on the final error of the method for the 3 search heuristics. The cascading effect causes a small error in the score to be exaggerated by the search method.\relax }}{5}}
\newlabel{fig:cascading}{{4}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Pre-Processing - Up/Down Orientation Detection}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Figures {\bf  a} and {\bf  b} show full reconstructions on the cross-cut variant (64\% correct) and the strip-cut variant (100\%correct). Figure {\bf  c} shows a partial reconstruction (with a threshold of 99.5\%) which successfully reduces the search space from 49 to 10 shreds while not introducing any errors.\relax }}{6}}
\newlabel{fig:searchRez}{{5}{6}}
\citation{P1,P5}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Figure {\bf  a} shows an example of inner and outer rows for one word and Figure {\bf  b} shows the corresponding upper and lower regions. Figure {\bf  c} shows the results obtained by using these upper and lower regions for orientation detection.\relax }}{7}}
\newlabel{fig:rowOrient}{{6}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions and Future Work}{7}}
\bibstyle{plain}
\bibdata{unshredder}
\bibcite{P12}{1}
\bibcite{P7}{2}
\bibcite{P10}{3}
\bibcite{P11}{4}
\bibcite{P6}{5}
\bibcite{P13}{6}
\bibcite{P8}{7}
\bibcite{P2}{8}
\bibcite{P1}{9}
\bibcite{P3}{10}
\bibcite{P4}{11}
\bibcite{P9}{12}
\bibcite{P5}{13}
\bibcite{P14}{14}
